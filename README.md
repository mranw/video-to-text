# Video-to-Text Processor & Knowledge Base Builder

Данный проект представляет собой комплексное решение для автоматизированной обработки видеофайлов с Яндекс.Диска с последующим созданием базы знаний на основе расшифрованных курсов. Конечная цель проекта – интеграция с LLaMA для создания AI-ассистента, который сможет отвечать клиентам на вопросы на основе извлечённой информации.

На текущем этапе реализованы следующие задачи:
- Рекурсивный обход папок на Яндекс.Диске и поиск видеофайлов.
- Скачивание видеофайлов для временной обработки.
- Извлечение аудиодорожки из видео с использованием **ffmpeg** с принудительным преобразованием в **OGG Opus** (моно, 48000 Гц, 64k битрейт).
- Определение длительности аудиофайла с помощью **ffprobe**.
- Загрузка аудиофайла в **Yandex Object Storage**.
- Асинхронное распознавание аудио через [Yandex SpeechKit](https://cloud.yandex.ru/services/speechkit) с использованием API-ключа или IAM-токена, с динамическим или фиксированным интервалом опроса статуса в зависимости от выбранного режима распознавания.
- Сохранение распознанного текста в единый файл без перезаписи уже имеющейся информации.
- Отметка обработанных видеофайлов для предотвращения повторного распознавания.
- Демонический режим работы с логированием и обработкой ошибок.

Кроме того, реализован первый этап формирования базы знаний:
- Обработка полученного текста (очистка от лишних символов и шумов).
- Разбиение текста на логические фрагменты (по курсам, разделам, урокам).
- Структурирование информации в виде базы знаний (формат question-answer) с классификацией по уровню значимости (актуальная и архивная информация).

В дальнейшем планируется интеграция с LLaMA с использованием метода Retrieval-Augmented Generation (RAG) для создания AI-ассистента.

## Структура проекта

Проект разделён на несколько модулей для повышения читаемости и масштабируемости:

```
project/
├── main.py               # Точка входа: объединяет работу всех модулей
├── video_processor.py    # Обработка видео: скачивание, извлечение аудио, распознавание речи
├── text_structurer.py    # Очистка и структурирование расшифрованного текста в базу знаний
├── database.py           # Функции для работы с базой знаний (сохранение, обновление, поиск)
├── utils.py              # Вспомогательные функции и конфигурация проекта
└── requirements.txt      # Зависимости проекта
```

## Требования

- **Python 3.x**
- Пакеты Python: `requests`, `boto3`, `python-dotenv` и другие, перечисленные в `requirements.txt`
- **ffmpeg** и **ffprobe** (должны быть установлены в системе)
- OAuth-токен для Яндекс.Диска
- API-ключ для Yandex SpeechKit или IAM-токен сервисного аккаунта для SpeechKit
- Доступ к **Yandex Object Storage**

## Установка и настройка

### 1. Клонирование репозитория

```bash
git clone https://github.com/yourusername/video-to-text.git
cd video-to-text
```

### 2. Создание виртуального окружения

Для изолированного запуска демона рекомендуется создать виртуальное окружение (например, в каталоге `/opt`):

```bash
sudo mkdir -p /opt/video-to-text
sudo chown $USER:$USER /opt/video-to-text
cd /opt/video-to-text
python3 -m venv venv
source venv/bin/activate
```

### 3. Установка зависимостей

Находясь в активированном виртуальном окружении, выполните:

```bash
pip install --upgrade pip
pip install -r /path/to/video-to-text/requirements.txt
```

> **Примечание:** Замените `/path/to/video-to-text/` на фактический путь к репозиторию.

### 4. Создание и настройка файла `.env`

В корневой директории проекта создайте файл `.env` со следующим содержимым:

```ini
YANDEX_DISK_OAUTH_TOKEN=your_yandex_disk_token
YANDEX_SPEECHKIT_API_KEY=your_speechkit_api_key
# Если используется IAM-токен для SpeechKit, укажите его:
YANDEX_SPEECHKIT_IAM_TOKEN=your_service_account_iam_token
YOBJECT_STORAGE_ACCESS_KEY=your_yandex_object_storage_access_key
YOBJECT_STORAGE_SECRET_KEY=your_yandex_object_storage_secret_key
```

### 5. Настройка сервиса systemd для автозапуска

Создайте файл сервиса, например, `/etc/systemd/system/video_to_text.service`:

```ini
[Unit]
Description=Video to Text Processor & Knowledge Base Builder
After=network.target

[Service]
ExecStart=/opt/video-to-text/venv/bin/python /path/to/video-to-text/main.py
WorkingDirectory=/path/to/video-to-text
Restart=always
User=your_user
EnvironmentFile=/path/to/video-to-text/.env

[Install]
WantedBy=multi-user.target
```

> **Примечание:**  
> - Замените `/path/to/video-to-text` на фактический путь к проекту.  
> - Замените `your_user` на имя пользователя, под которым будет запускаться сервис.

### 6. Запуск и проверка сервиса

После настройки сервиса выполните:

```bash
sudo systemctl daemon-reload
sudo systemctl enable video_to_text.service
sudo systemctl start video_to_text.service
sudo systemctl status video_to_text.service
```

## Работа проекта

- **Видео-процессор:**  
  Модуль `video_processor.py` осуществляет автоматический обход папок на Яндекс.Диске, скачивание видео, извлечение аудио, загрузку в Object Storage и асинхронное распознавание речи с динамическим или фиксированным интервалом опроса в зависимости от выбранной модели (`general` или `deferred-general`).

- **Обработка текста:**  
  Модуль `text_structurer.py` очищает расшифрованный текст, разбивает его на логические секции (по курсам, разделам, урокам) и структурирует в формат базы знаний (question-answer), классифицируя фрагменты по уровню важности.

- **База знаний:**  
  Результаты обработки сохраняются в файл `knowledge_base.json` или могут быть интегрированы с системой управления базой (через модуль `database.py`). Это позволит на следующем этапе интегрировать данные с LLaMA.

- **Интеграция с LLaMA (будущая доработка):**  
  Планируется запустить LLaMA (например, с использованием llama.cpp) и дообучить её на материалах Школы Насти Рыбки. При использовании метода Retrieval-Augmented Generation (RAG) модель сначала будет искать нужные фрагменты в базе знаний, а затем формировать ответ для клиента.

- **Логирование и устойчивость:**  
  Все операции, ошибки и события логируются в файл `video_processor.log`. Сервис работает в демоническом режиме с периодическим сканированием (каждые 12 часов) и предотвращением повторной обработки уже обработанных видеофайлов.

## Лицензия

Этот проект распространяется под лицензией **MIT License**.

## Контрибьюция

Если вы хотите внести вклад или у вас есть предложения по улучшению проекта, пожалуйста, создайте issue или pull request в репозитории.